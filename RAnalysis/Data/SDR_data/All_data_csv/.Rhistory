library("XML")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=1805010000&days=30") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=1805010000&days=15") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180702&days=7") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","Temp_T3",
"pH_T3", "TMP_T1", "pH_T1")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180702_Apex_Data_Output.data.csv") #write file to save data
#http://www.informit.com/articles/article.aspx?p=2215520
# modified as of 20170702 by SJG
#  cahnges in lines 20 - 36
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180627&days=6") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
# Column names modified as of 20180702
# Date.Time = column 2
# TMP_T2 = column 6
# pH_T2= column 9
# salinity = column 12
# TMP_T4 = column 66
# pH_T4 = column 69
# TMP_T5 = column 72
# pH_T5 = column 75
# TMP_T3 = column 78
# pH_T3 = column 81
# NOTE: 10 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T2", "pH_T2", "Sal", "TMP_T4", "pH_T4","Temp_T5",
"pH_T5", "TMP_T3", "pH_T3")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180702_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180702_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T5)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180627&days=6") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T2", "pH_T2", "Sal", "TMP_T4", "pH_T4","Temp_T5",
"pH_T5", "TMP_T3", "pH_T3")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180702_Apex_Data_Output.data.csv") #write file to save data
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180702_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T5)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180702&days=7") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","Temp_T3",
"pH_T3", "TMP_T1", "pH_T1")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180708_Apex_Data_Output.data.csv") #write file to save data
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180708_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T5)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180708_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#http://www.informit.com/articles/article.aspx?p=2215520
#modified as of 20180715 SJG
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
#changes in lines 20 - 36 for column name changes for switched conicals -> 20170708 by SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180708&days=8") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
# Column names modified as of 20180707
# Date.Time = column 2
# TMP_T0 = column 6
# pH_T0= column 9
# salinity = column 12
# TMP_T2 = column 66
# pH_T2 = column 69
# TMP_T3 = column 72
# pH_T3 = column 75
# TMP_T1 = column 78
# pH_T1 = column 81
# NOTE: 10 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","Temp_T3",
"pH_T3", "TMP_T1", "pH_T1")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180715_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180715_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
?LoLinR
resp<-read.table(file.choose(), header=T, sep=",")
resp
library(LoLinR)
data(BugulaData)
BugalaRegs<-rankLocReg(
xall-resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
BugalaRegs<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
BugalaRegs<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
BugalaRegs<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
BugalaRegs<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
BugalaRegs
summary(BugalaRegs)
resp_H0_T<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
resp_H0_T<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
resp_H0_T
summary(resp_H0_T)
resp_H0_T<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
resp_H0_T<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
resp_H0_T<-rankLocReg(
xall=resp$Date.Time,yall=resp$A1,
alpha=0.2, method="eq")
resp_H0_T
summary(resp_H0_T)
resp_H1_T <-rankLocReg(
xall=resp$Date.Time,yall=resp$A4,
alpha=0.2, method="eq")
summary(resp_H1_T)
resp_H0_B<-rankLocReg(
xall=resp$Date.Time,yall=resp$B1,
alpha=0.2, method="eq")
summary(resp_H0_B)
resp_H1_B<-rankLocReg(
xall=resp$Date.Time,yall=resp$B4,
alpha=0.2, method="eq")
summary(resp_H1_B)
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180724&days=9") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","Temp_T3",
"pH_T3", "TMP_T1", "pH_T1")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180801_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180801_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#http://www.informit.com/articles/article.aspx?p=2215520
#modified as of 20180715 SJG
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
#changes in lines 20 - 36 for column name changes for switched conicals -> 20170708 by SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180801&days=5") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
# Column names modified as of 20180707
# Date.Time = column 2
# TMP_T0 = column 6
# pH_T0= column 9
# salinity = column 12
# TMP_T2 = column 66
# pH_T2 = column 69
# TMP_T3 = column 72
# pH_T3 = column 75
# TMP_T1 = column 78
# pH_T1 = column 81
# NOTE: 10 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","Temp_T3",
"pH_T3", "TMP_T1", "pH_T1")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180805_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180805_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=1800805&days=10") #read in the date plus x days of Apex data
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=1800805&days=10") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=1800805&days=10") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=180805&days=10") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81)] #select columns
colnames(Probe.Data ) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","Temp_T3",
"pH_T3", "TMP_T1", "pH_T1")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/20180814_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/Apex_data/Output/Graphs/20180814_Apex_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(12, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(Temp_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(7.1, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
library(plyr)
# NOTE & Assumptions:
# character-matching plays a major role in this script- a merge, an if statement, and mean calculations are based on characters
# units in the called files (column name "bi.Lpc") are assumed to be umol min-1 when uploaded to the script
# current script is written for 10 files each with 16 runs of the SensorDish (SDR) 24-well plate
###################################################################################################
rm(list=ls())
#set working directory--------------------------------------------------------------------------------------------------
setwd("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/Data/SDR_data/All_data_csv")
main<-getwd()
# path used in the loop to each file name indicated in Table_files (matrix of filenames created below)
path<-"Cumulative_output/" #the location of all your respiration files
# make a table for all the filenames to call
table_o_files <- data.frame(matrix(nrow = 10))
table_o_files$rownumber <- c(1,2,3,4,5,6,7,8,9,10)
table_o_files$name <- c("Cumulative_resp_individually_all.csv",
"Cumulative_resp_alpha0.2_all.csv", "Cumulative_resp_alpha0.2_min10-20.csv", "Cumulative_resp_alpha0.2_min10-25.csv",
"Cumulative_resp_alpha0.4_all.csv", "Cumulative_resp_alpha0.4_min10-20.csv", "Cumulative_resp_alpha0.4_min10-25.csv",
"Cumulative_resp_alpha0.6_all.csv", "Cumulative_resp_alpha0.6_min10-20.csv", "Cumulative_resp_alpha0.6_min10-25.csv")
table_o_files$matrix.nrow...10. <- NULL
# make a dataframe to rbind the ouput
cumulative_respCALC <- data.frame(matrix(nrow = 384, ncol = 16)) # 384 is the size of each file
# composed of cumulative LoLin regression anlaysis of 16 files with
# 24 measurements (rows) each (12 animals + 12 replicates per "RUN")
# names here are the same order as the imported files in table_o_filenames$name
colnames(cumulative_respCALC) <- c("Resp_individually_all.csv",
"LpcResp_alpha0.2_all.csv", "LpcResp_alpha0.2_min10-20.csv", "LpcResp_alpha0.2_min10-25.csv",
"LpcResp_alpha0.4_all.csv", "LpcResp_alpha0.4_min10-20.csv", "LpcResp_alpha0.4_min10-25.csv",
"LpcResp_alpha0.6_all.csv", "LpcResp_alpha0.6_min10-20.csv", "LpcResp_alpha0.6_min10-25.csv", # now has 10 columns for each file output
"Date", "SDR_pos", "RUN", "tank", "Day_trial", "Treat1_Treat2")
# OUTSIDE FOR LOOP --------------------------------------------------------------------------------
# calls each target file in the data.frame created above; all files are within the folder specified in the path
for(i in 1:nrow(table_o_files)){
resp<-read.csv(file.path(path, (table_o_files[i,2])), header=T, sep=",", na.string="NA", as.is=T)
#resp<-read.csv(file.path(path, "Cumulative_resp_individually_all.csv"))
resp
# the inside loop depends on the order of the file - must be ordered by "Date" and by "RUN"
resp_sorted <- resp[
with(resp, order(resp$Date, resp$RUN)),
]
resp_sorted
resp_sorted$newname <- paste(
resp_sorted$Date, (substr(resp_sorted$tank, 1, 4)), (substr(resp_sorted$ID, 6, 10)), sep="_")
dataMEANS <- ddply(resp_sorted, "newname", summarise, mean = mean(abs(b1.Lpc)))
MEANSblanks <- dataMEANS[(which(nchar(dataMEANS$newname) == 19)),]
resp_sorted_2 <- merge(resp_sorted,MEANSblanks, by="newname", all = TRUE, sort = T)
###########################################################################################begin from here
resp_sorted_2$row <- seq.int(nrow(resp_sorted_2))
for (j in 1:nrow(resp_sorted_2)){
resp_sorted_2$resprate_CORRECTED <- ((abs(resp_sorted_2$b1.Lpc)) - (resp_sorted_2$mean[(resp_sorted_2$row+3)]))
resp_sorted_2$resprate_CORRECTED
# bind the columns in cumulative resp sequentially with the files uploaded and calculated (NOTE: names in table_o_filename are SAME ORDER for Cumulatice_respCALC)
resp_sorted_2$resprate_CALC <- ((((resp_sorted_2$resprate_CORRECTED/(1000/4))*(60))*31.998)/(resp_sorted_2$number_indivs*resp_sorted_2$mean_size))
resp_sorted_2
}
# This small function eliminates a datafram based on NA of a certain columns
# In this case, the NA are in resprate_CALC
desiredCols <- resp_sorted_2[,c(3,4,5,7,10,11,12,16,19)]
completeFun <- function(resp_sorted_2,  desiredCols) {
completeVec <- complete.cases(resp_sorted_2[, desiredCols])
return(resp_sorted_2[completeVec, ])
}
resp_FINAL<-completeFun(resp_sorted_2, "resprate_CALC")
resp_FINAL <- resp_sorted_2[
with(resp_sorted_2, order(resp_sorted_2$Date, resp_sorted_2$RUN, resp_sorted_2$SDR_position)),
]
cumulative_respCALC[,i] <- resp_FINAL$resprate_CALC
#cumulative_respCALC[,1] <- resp_sorted$resprate_CALC
cumulative_respCALC
print(cumulative_respCALC)
# write the output
cumulative_respCALC[,11] <- resp_sorted$Date
cumulative_respCALC[,12] <- resp_sorted$SDR_position
cumulative_respCALC[,13] <- resp_sorted$RUN
cumulative_respCALC[,14] <- resp_sorted$tank
cumulative_respCALC[,15] <- resp_sorted$Day_Trial
cumulative_respCALC[,16] <- resp_sorted$Treat1_Treat2
cumulative_respCALC[,c(11,12,13,14,15,16,1,2,3,4,5,6,7,8,9,10)]
} # closed OUTSIDE for loop
# This small function eliminates a datafram based on NA of a certain columns
# In this case, the NA are in resprate_CALC
desiredCols2 <- cumulative_respCALC[,c(11,12,13,14,15,16,1,2,3,4,5,6,7,8,9,10)] # we want all of the columns
completeFun <- function(cumulative_respCALC,  desiredCols2) {
completeVec <- complete.cases(cumulative_respCALC[, desiredCols2])
return(cumulative_respCALC[completeVec, ])
}
# eliminates all rows with NA in "LpcResp_alpha0.6_min10-25.csv"
cumulative_respCALC_FINAL <-   resp_FINAL<-completeFun(cumulative_respCALC, "LpcResp_alpha0.6_min10-25.csv") # choose an example of a data file
print(cumulative_respCALC_FINAL)
write.table(cumulative_respCALC_FINAL,"All_resp_calc_and_standardized.csv",sep=",", row.names=FALSE)
